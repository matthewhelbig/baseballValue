---
title: "Baseball Value"
author: "Matthew Helbig"
date: '2019-09-28'
output:
  pdf_document:
    toc: true
---

#Introduction

The goal of this project is to identify the attributes of the players with the most value and the least value,
as well as predicting which players will have the most and least value in the future.

#Getting started

The first step we'll take is to identify which datasets we'll be working with. The Lahman Database has a lot of good information that we'll need, namely Player Value data, salary, and dates of birth. 

We'll download that from <http://www.seanlahman.com/baseball-archive/statistics/>

It's possible to download the database as a .CSV file, and you could technically do everything needed for this project without using SQL, but it's a good practice to get used to working with databases, especially since a lot of the datasets you'd see in the real world will be bigger than the one we're currently working with.

Sean Lahman has posted the entire .sql file on his website, so importing it into MySQL is as simple as hitting 'Data Import' and loading that database into its own schema.

Once the Lahman database is all settled in its own schema, we want to start to work with that data. There are packages that let you run SQL commands inside R, and there is definitely some value in not having to hop back and forth between R and your SQL environments. However, I'm more comfortable working in MySQL directly, so we won't worry too much about those R-SQL packages (namely RMySQL).

#Setting things up in SQL

The three tables that we're most interested in right now are "Batting," "Pitching," and "Salaries." The database has a ton of information that's interesting, but ultimately not super useful for our experiment. For our project, we're going to use data from 2006 to 2010 to find our "model" player, and then use data from 2011 to 2016 to test if our hypothesis is true.

##"Subsetting" our Batting data
We'll need to create a new table in SQL based on our criteria of only needing 2006 and later (this database ends in 2016).

```{sql, eval = FALSE}
CREATE TABLE Batting_post_2006
LIKE Batting
```

Now we've created a table with the same containers as our Batting table, and now we need to load the data into those containers.

```{sql, eval = FALSE}
INSERT INTO Batting_post_2006
SELECT *
FROM Batting;
```

Now we're going to trim our data from our new table in order to limit ourselves to only 2006 to 2016. This is where SQL is beneficial, since our original dataset of "Batting" is complete safe and untouched.

```{sql, eval = FALSE}
DELETE FROM Batting_post_2006
WHERE yearID < 2006
```

We're going to do the same thing with our Salaries table, and eventually our Pitching table. We won't do the Pitching table just yet, but we can follow these same steps in order to set that table up for export to R. For now, we'll work on the Salaries table:

```{sql, eval = FALSE}
CREATE TABLE Salaries_post_2006
LIKE Salaries
```

```{sql, eval = FALSE}
INSERT INTO Salaries_post_2006
SELECT *
FROM Salaries;
```

```{sql, eval = FALSE}
DELETE FROM Salaries_post_2006
WHERE yearID < 2006
```

Here, we created a new table to put our data in, moved all of our data from the Salaries table into it, and then limited ourselves to data after 2016. Once again, the original Salaries table is untouched.

##Joining Birth Year and Salary
One important step that hasn't happened yet is getting birth year statistics from the Master table in the database. This will allow us to create an Age variable in R later, which will be a potentially key attribute for determining who is overvalued and undervalued. In order to add birth year to our Salary data, we'll need to join the two tables.

First, we create a new container for our combined data:

```{sql, eval = FALSE}
CREATE TABLE Player_Salary_Info (
    AutoNum int NOT NULL AUTO_INCREMENT,
    playerID varchar(255),
    birthyear int,
    yearID int,
    salary int,
	PRIMARY KEY (AutoNum)
);
```

The AutoNum variable is important here, because we need something as the primary key, and if we were to use playerID then we'd have duplicate values between Salary and Master (since the playerIDs are the same between the two tables).

Next, we'll populate our new table with data:
```{sql, eval = FALSE}
INSERT INTO Player_Salary_Info 
SELECT 0, Salaries_post_2006.playerID, Master.birthYear, 
Salaries_post_2006.yearID, Salaries_post_2006.salary
FROM Salaries_post_2006 
INNER JOIN Master ON Salaries_post_2006.playerID = Master.playerID
```


So now we know that we've managed to get playerID, birthyear, yearID, and salary in the same spot. Our next task will be combining this information with our Batting table, at which point we'll be able to move this new table over to R.

##Joining Birth Year, Salary, and Batting
One hiccup we face is that several of our variables for some reason are indicated as strings despite being numeric values. I've encountered issues with this before, where a value of 0 would return an empty string (like " ") instead of actually being 0. To solve this, we can change the string columns into integer columns using the following lines of code:

```{sql, eval = FALSE}
ALTER TABLE example
ADD newCol int;

UPDATE example SET newCol = CAST(column_name AS UNSIGNED);

ALTER TABLE example
DROP COLUMN column_name;

ALTER TABLE example
CHANGE COLUMN newCol column_name int;
```

Now that our data is in a format we can work with that won't give us (hopefully) any errors, we can create and populate our Batting table with salary added. We create the parameters for the new table:

```{sql, eval = FALSE}
CREATE TABLE Batting_Salary (
    AutoNum int NOT NULL AUTO_INCREMENT,
    playerID varchar(255),
    birthyear int,
    yearID int,
    salary int,
    stint int,
    teamID varchar(255),
    lgID varchar(255),
    G int,
    AB int,
    R int,
    H int,
    2B int,
    3B int,
    HR int,
    RBI int,
    SB int,
    CS int,
    BB int,
    SO int,
    GIDP int,
    SF int,
    SH int,
    HBP int,
    IBB int,
	PRIMARY KEY (AutoNum)
);
```

Now we populate our new table:

```{sql, eval = FALSE}
INSERT INTO Batting_Salary
SELECT 0, Batting_post_2006.playerID, Player_Salary_Info.birthyear, 
Player_Salary_Info.yearID, Player_Salary_Info.salary, Batting_post_2006.stint, 
Batting_post_2006.teamID, Batting_post_2006.lgID, Batting_post_2006.G, 
Batting_post_2006.AB, Batting_post_2006.R, Batting_post_2006.H, 
Batting_post_2006.2B, Batting_post_2006.3B, Batting_post_2006.HR, 
Batting_post_2006.RBI, Batting_post_2006.SB, Batting_post_2006.CS, 
Batting_post_2006.BB, Batting_post_2006.SO, Batting_post_2006.GIDP, 
Batting_post_2006.SF, Batting_post_2006.SH, Batting_post_2006.HBP, 
Batting_post_2006.IBB    
FROM Batting_post_2006
INNER JOIN Player_Salary_Info ON Player_Salary_Info.playerID = Batting_post_2006.playerID 
AND Player_Salary_Info.yearID = Batting_post_2006.yearID
```

So now we've successfully combined our tables with salary information, birth year information, and batting statistics into one table called Batting_Salary. In the process, we also already shaped the data so that it's only dealing with the years we're concerned with (2006 to 2016). We're just one step away from having our Batter data ready for analysis in R. That step is getting our player value data from Baseball-Reference.

##Getting player value data from Baseball-Reference

Our first step is to head to <https://www.baseball-reference.com/data/>, where they keep a daily log of player value data for every player in baseball history. Player value is measured in a lot of different ways, and a constant source of contention in the baseball community is which metrics provide the most accurate measurement of a player's true value. 

The player value metric we'll be focusing on the most is Wins Above Replacement (abbreviated as WAR), which measures how many wins a player provided to his team compared to a random player that you could find in the minor leagues. As a rough translation, consider WAR to be the "stock price" of MLB players, as it gives a simple and quick approximation of the value of a player (or stock).

The information we're looking for is all the way at the bottom of the page, under "war_daily_bat.txt." We'll download that, and convert it to .csv using a spreadsheet program (I'm using Open Office). Just follow the steps for converting everything, and we'll save it to our active folder.

Now we need to load this data into SQL. However, if we look at this data in R:


```{r}
Daily_bat <- read.csv("war_daily_bat.csv")
names(Daily_bat)
```

We can see that we have a ton of variables that we don't necessarily want. Remember when we created a container in SQL above? If we were to try to read this into SQL now, we'd have to create a container for every one of these variables. We don't necessarily need "oppRpG," which measures how many runs per game that player's opponent scored. Similarly, we don't need a lot of other variables. We're going to limit ourselves to just the ones we want to keep by running the following (Note: you'll need the "dplyr" library for this function):

```{r, message=FALSE, echo=FALSE}
library(dplyr)
```

```{r}
kept_Columns = select(Daily_bat, 1, 2, 4, 5, 6, 31, 32, 33, 36, 47)
```

Which is going to keep only the columns we're interested in, namely:

```{r}
names(kept_Columns)
```

Next we're going to subset our data to keep it within the year range we're investigating (2006 to 2016), as well as limiting our data to be only batters, since we really aren't interested in how pitchers hit. Although the data we'll be analyzing is from 2006 to 2015, we'll also include 2016 as a potential year to see if our hypothesis is true. If a player is identified as a "pre-breakout" candidate in 2015, we can use 2016 to see if he did break out. Obviously, since the dataset doesn't include 2017, we won't be able to see if "pre-breakout" players in 2016 actually had good years in 2017. Pitchers aren't paid based on their ability to hit, so batting statistics for pitchers aren't relevant to what we're studying.
```{r}
years_pitchers_Subset <- subset(kept_Columns, 2005 < year_ID & year_ID < 2017 & pitcher == "N")
```

Finally, we'll remove the pitcher column, since all of our kept players are going to be batters:

```{r}
Batting_value <- select(years_pitchers_Subset, -9)
```

After all this, we're ready to export this data from R and into SQL so we can join it with our Batting_Salary table.

```{r}
write.csv(Batting_value, "Batting_Value.csv")
```

We create our container in SQL by running the following:

```{sql, eval = FALSE}
CREATE TABLE Batting_Value (
    AutoNum int NOT NULL AUTO_INCREMENT,
    name_common varchar(255),
    age int,
    player_ID varchar(255),
    year_ID int,
    team_ID varchar(255),
    WAR DECIMAL(4,2),
    WAR_def DECIMAL(4,2),
    WAR_off DECIMAL(4,2),
    OPS_plus int,
	PRIMARY KEY (AutoNum)
);
```

Then we'll load our data into the container using the following command:

```{sql, eval = FALSE}
LOAD DATA LOCAL INFILE '/filepath/Batting_Value.csv'
INTO TABLE Batting_Value FIELDS TERMINATED BY ','
ENCLOSED BY '"' LINES TERMINATED BY '\n'
IGNORE 1 LINES
```

Now we want to combine this data with our Batting_Salary data so we can have our final dataset to work with in R.

We'll create the container we'll use for our combined data:
```{sql, eval = FALSE}
CREATE TABLE Value_Salary (
    AutoNum int NOT NULL AUTO_INCREMENT,
    playerID varchar(255),
    name_common varchar(255),
    yearID int,
    age int,
    salary int,
    stint int,
    teamID varchar(255),
    lgID varchar(255),
    G int,
    AB int,
    R int,
    H int,
    2B int,
    3B int,
    HR int,
    RBI int,
    SB int,
    CS int,
    BB int,
    SO int,
    GIDP int,
    SF int,
    SH int,
    HBP int,
    IBB int,
    WAR DECIMAL(4,2),
    WAR_def DECIMAL(4,2),
    WAR_Off DECIMAL(4,2),
    OPS_plus int,
	PRIMARY KEY (AutoNum)
);
```

Then we load in our data:

```{sql, eval = FALSE}
INSERT INTO Value_Salary
SELECT DISTINCT 0,
Batting_Salary.playerID,
Batting_Value.name_common,
Batting_Salary.yearID,
Batting_Value.age,
Batting_Salary.salary,
Batting_Salary.stint,
Batting_Salary.teamID,
Batting_Salary.lgID,
Batting_Salary.G,
Batting_Salary.AB,
Batting_Salary.R,
Batting_Salary.H,
Batting_Salary.2B,
Batting_Salary.3B,
Batting_Salary.HR,
Batting_Salary.RBI,
Batting_Salary.SB,
Batting_Salary.CS,
Batting_Salary.BB,
Batting_Salary.SO,
Batting_Salary.GIDP,
Batting_Salary.SF,
Batting_Salary.SH,
Batting_Salary.HBP,
Batting_Salary.IBB,
Batting_Value.WAR,
Batting_Value.WAR_def,
Batting_Value.WAR_off,
Batting_Value.OPS_plus    
FROM Batting_Salary
INNER JOIN Batting_Value ON Batting_Salary.playerID = Batting_Value.player_ID AND Batting_Salary.yearID = Batting_Value.year_ID
```


As a note, this table works very well until it comes to the players who were traded in the middle of the season. When a player hasn't been traded, there is one row per year. However, when a player has been traded, we would expect to see two columns that year (one for the old team, one for the new team). However, we see four:

```{r, echo=FALSE, message=FALSE}
Pre_Batting_Value_Salary <- read.csv("Value_Salary.csv")
show_duplicates <- subset(Pre_Batting_Value_Salary, AutoNum == 1:6)
```

```{r, echo = FALSE}
head(show_duplicates[,1:7])
```

##Split, apply, combine?
We need to remove those duplicates, and one very common way of doing so is via a process often used in data analysis called "Split, apply, combine."

This process involves splitting the data into subsets, applying a function to each subset, and then combining the data back together. Which is what we want to do here. We want to remove the duplicate players from every year, but we don't want to remove duplicates from the dataset as a whole. For example, there are multiple "Bobby Abreu" rows in our 2006 data, which we would like to reduce to a single row. However, we don't want to remove all of the "Bobby Abreu" rows from our master dataset, because that would remove Bobby Abreu's stats for 2007, 2008, and so on.

We could subset our data by year, write a function that removes duplicates for each year, and then join all of our subsets back together. Or, we could use a library that we've already called, the 'dplyr' library, and remove the duplicates by year from our main dataset.

If we execute the following command:
```{r}
Batting_Value_Salary <- Pre_Batting_Value_Salary %>%
  distinct(playerID, yearID, .keep_all = TRUE)
```

We can see that we've successfully removed the duplicates:
```{r, echo = FALSE}
head(Batting_Value_Salary[,1:7])
```

This is a nice way of using pre-built libraries to limit the amount of code that you need to write. The dplyr library has a ton of functions like this, and we'll make use of them when we further analyze our data in R.

There we go! Our Batting Value data is all ready for analysis in R. It took a lot of behind the scenes work, but it left us with some very high quality data on which to test our hypotheses.

#Working with our Batting Value Data

Now that we have everything loaded in and set up properly, we're going to begin the actual analysis step of this project. We spent a ton of time loading in the necessary variable in order to work with our data, but there are still more new variables that will help us draw even deeper conclusions.

##Creating variables

###Cost-per-win
Since we have wins above replacement data and salary data, we can create a new variable called "cost-per-win" that will let us know how expensive a win is on the open market. If a team were to go out and sign a player, the "cost-per-win" would be how much it would cost, on average, to buy 1 win above replacement. That data has been collected online, and we're going to use the data from "https://batflipsandnerds.com/2018/06/20/the-modern-myths-of-baseball-the-cost-of-a-win/"

These values change every year, so we'll need to make sure that the specific cost-per-win is applied to the appropriate year. In order to do this, we'll need to do another split-apply-combine on our data.

First we'll split the data by year:
```{r}
year <- split(Batting_Value_Salary, Batting_Value_Salary$yearID)
```

Then we'll apply the appropriate cost-per-win to each year:
```{r}
year$`2006`$cost_per_win <- 4600000
year$`2007`$cost_per_win <- 5300000
year$`2008`$cost_per_win <- 5600000
year$`2009`$cost_per_win <- 5700000
year$`2010`$cost_per_win <- 5800000
year$`2011`$cost_per_win <- 6400000
year$`2012`$cost_per_win <- 6900000
year$`2013`$cost_per_win <- 7500000
year$`2014`$cost_per_win <- 7700000
year$`2015`$cost_per_win <- 8700000
year$`2016`$cost_per_win <- 9600000
```

Finally, we'll combine our data back together now that we've split it by year and applied the appropriate cost-per-win:
```{r}
Batting_Value_Salary <- rbind(year$`2006`, year$`2007`, year$`2008`, year$`2009`, year$`2010`, year$`2011`, year$`2012`, year$`2013`, year$`2014`, year$`2015`, year$`2016`)
```

###Player Money Value
The next variable we're going to create is going to be "Player Money Value." This is going to capture how much value, in dollars, a player provided that season. We'll do this by multiplying a player's wins above replacement by the cost of a win above replacement. This number will essentially be how much a player was worth if they had been available on the open market and received fair market value. This is how we'll do it:
```{r}
Batting_Value_Salary$player_money_value <- (Batting_Value_Salary$WAR * Batting_Value_Salary$cost_per_win)
```

###Value Plus
It's important to de-contextualize a player's value. For example, if we said that Joe Random provided $6 million in value, we wouldn't know off the top of our heads if that was good or bad. We'd need to know how much value everyone else was providing. "Value Plus" is a statistic that allows us to do that. It normalizes the value a player provides, where 100 is average. If a player has a Value Plus of 120, it means that they provided 20% more value than average. We'll calculate this by doing the following:
```{r}
Batting_Value_Salary$value_plus <- ((Batting_Value_Salary$player_money_value / mean(Batting_Value_Salary$player_money_value)*100))
```

###Excess value
The next variable we'll need is "Excess value." This will measure the difference between how much a player was worth and how much they actually made. It's worth noting that for some players, especially good players with low salaries (i.e. players still on their rookie contracts), this number will be quite high. For some players, this number could be in the negatives, indicating that they cost their team money with their play. We'll calculate this as follows:
```{r}
Batting_Value_Salary$excess_value <- (Batting_Value_Salary$player_money_value - Batting_Value_Salary$salary)
```

###Excess value plus
The final variable we'll be working with right now is "Excess Value Plus." This will be a normalized version of "Excess value" in order to give a more accurate and context-free representation of the excess value for each player. While knowing how valuable a player was with respect to other players, it's even more valuable to know how much excess value they provided relative to other players. This is very similar to our "Value Plus" statistic, except this new variable also incorporates a player's salary into it. Here's how we'll calculate it:
```{r}
Batting_Value_Salary$excess_value_plus <- ((Batting_Value_Salary$excess_value / mean(Batting_Value_Salary$excess_value)*100))
```

###Batting average, On-Base Percentage, Slugging Percentage, OPS, and ISO
We've mostly created sabermetric statistics thus far, but in order to identify potential undervalued and overvalued players, it will help to use some traditional statistics as well.

Batting average measures how many hits a player gets per at-bat, on-base percentage measures how often a player gets on-base per at-bat, and slugging percentage measures how many bases a player obtains per at-bat (essentially, how hard does he hit the ball).

We'll calculate batting average as follows:
```{r}
pre_batting_average <- (Batting_Value_Salary$H)/(Batting_Value_Salary$AB)
Batting_Value_Salary$batting_average <- round(pre_batting_average, digits = 3)
```

Next, we'll calculate on-base percentage:
```{r}
pre_on_base_percentage <- (Batting_Value_Salary$H + Batting_Value_Salary$BB + Batting_Value_Salary$HBP)/(Batting_Value_Salary$AB + Batting_Value_Salary$BB + Batting_Value_Salary$HBP + Batting_Value_Salary$SF)
Batting_Value_Salary$on_base_percentage <- round(pre_on_base_percentage, digits = 3)
```

Then we'll calculate slugging percentage:
```{r}
pre_slugging_percentage <- ((Batting_Value_Salary$H - Batting_Value_Salary$X2B - Batting_Value_Salary$X3B - Batting_Value_Salary$HR) + (Batting_Value_Salary$X2B * 2) + (Batting_Value_Salary$X3B * 3) + (Batting_Value_Salary$HR * 4))/
  (Batting_Value_Salary$AB)
Batting_Value_Salary$slugging_percentage <- round(pre_slugging_percentage, digits = 3)
```

OPS, or on-base plus slugging, is a statistics that, simply put, combines on-base-percentage and slugging percentage. It's a quick way to see how often a guy got on baseball, and how hard he hit the ball to get on base.
```{r}
Batting_Value_Salary$OPS <- (Batting_Value_Salary$on_base_percentage) + (Batting_Value_Salary$slugging_percentage)
```

ISO, or isolated power, is another quick metric to determine how powerful someone was at the plate. The higher the ISO, the more bases someone accumulated relative to their batting average. It's not super helpful as a predictive statistic, but it
will give us another tool to work with when we're doing our player similarity evaluations.
```{r}
Batting_Value_Salary$ISO <- (Batting_Value_Salary$slugging_percentage) - (Batting_Value_Salary$batting_average)
```

###Strikeout percentage and walk percentage
The final two statisics we'll create for the time being are going to measure plate discipline. Generally speaking, a low strikeout percentage and a high walk percentage are positive predictors of future success. In order to identify potential breakout players, we'll want to quantify these statistics to use for future evaluation.
```{r}
pre_SO_percentage <- ((Batting_Value_Salary$SO)/(Batting_Value_Salary$AB + Batting_Value_Salary$BB + Batting_Value_Salary$HBP + Batting_Value_Salary$SF)*100)
Batting_Value_Salary$SO_percentage <- round(pre_SO_percentage, digits = 2)
```

```{r}
pre_BB_percentage <- ((Batting_Value_Salary$BB)/(Batting_Value_Salary$AB + Batting_Value_Salary$BB + Batting_Value_Salary$HBP + Batting_Value_Salary$SF)*100)
Batting_Value_Salary$BB_percentage <- round(pre_BB_percentage, digits = 2)
```

##Context-free Strikeout and walk percentages

One issue we'll run into with strikeout and walk percentages is that those totals vary by year in the league. From 2006 to 2016, strikeouts varied from 16.8% in 2006 to 21.1% in 2016. Similarly, walk rates ranged from 7.6% in 2014 to 8.9% in 2009.

If we didn't correct for context, then a strikeout rate of 19% could be either above-average or below-average depending on the year. In order to solve this, we'll once again do a split-apply-combine technique to create our variables.

###Strikeout and walk percentages split-apply-combine
```{r}
year <- split(Batting_Value_Salary, Batting_Value_Salary$yearID)

year$`2006`$league_SO_percentage <- 16.8
year$`2006`$league_BB_percentage <- 8.4
year$`2007`$league_SO_percentage <- 17.1
year$`2007`$league_BB_percentage <- 8.5
year$`2008`$league_SO_percentage <- 17.5
year$`2008`$league_BB_percentage <- 8.7
year$`2009`$league_SO_percentage <- 18.0
year$`2009`$league_BB_percentage <- 8.9
year$`2010`$league_SO_percentage <- 18.5
year$`2010`$league_BB_percentage <- 8.5
year$`2011`$league_SO_percentage <- 18.6
year$`2011`$league_BB_percentage <- 8.1
year$`2012`$league_SO_percentage <- 19.8
year$`2012`$league_BB_percentage <- 8.0
year$`2013`$league_SO_percentage <- 19.9
year$`2013`$league_BB_percentage <- 7.9
year$`2014`$league_SO_percentage <- 20.4
year$`2014`$league_BB_percentage <- 7.6
year$`2015`$league_SO_percentage <- 20.4
year$`2015`$league_BB_percentage <- 7.7
year$`2016`$league_SO_percentage <- 21.1
year$`2016`$league_BB_percentage <- 8.2

Batting_Value_Salary <- rbind(year$`2006`, year$`2007`, year$`2008`, year$`2009`, year$`2010`, year$`2011`, 
               year$`2012`, year$`2013`, year$`2014`, year$`2015`, year$`2016`)
```
###Creating SO+ and BB+
```{r}
pre_SO_plus <- 
  ((Batting_Value_Salary$SO_percentage / Batting_Value_Salary$league_SO_percentage*100))
Batting_Value_Salary$SO_plus <- round(pre_SO_plus, digits = 2)

pre_BB_plus <- 
  ((Batting_Value_Salary$BB_percentage / Batting_Value_Salary$league_BB_percentage*100))
Batting_Value_Salary$BB_plus <- round(pre_BB_plus, digits = 2)
```
#Solving Issues by Subsetting

Now that we have all of our variables created, we seem like we're just about set to start getting to the meat of the project, and determining which players are the most undervalued and which are the most overvalued. 

However, some quick graphs will highlight an issue that we face, and this issue isn't so much with our data so much as it is with an underlying fact about Major League Baseball.

##Graphing Average Salary and Excess Value by Age

Since our main focus will be on the amount of excess value a player provided, and excess value is comprised of player value and salary, it will be key to focus on the average salaries for players in different age groups. This will demonstrate a bit where our problem lies.

###Salary Plus

First, we'll create a Salary+ metric that will normalize salary data relative to the average salary.
```{r}
Batting_Value_Salary$salary_plus <- ((Batting_Value_Salary$salary / mean(Batting_Value_Salary$salary)*100))
```

Next, we're going to calculate the mean salary by age, and then plot that to get a graphical representation of how salary changes as a player gets older.
```{r}
agg1 <- aggregate(x = Batting_Value_Salary$salary_plus, by = list(Batting_Value_Salary$age), FUN = mean)
names(agg1)[1] <- "Age"
names(agg1)[2] <- "Average Salary"
```

###Excess Value Plus
The second part of our graph will be Excess Value Plus by age, so we'll calculate the mean Excess Value Plus by Age as follows:
```{r}
agg2 <- aggregate(x = Batting_Value_Salary$excess_value_plus, by = list(Batting_Value_Salary$age), FUN = mean)
names(agg2)[1] <- "Age"
names(agg2)[2] <- "Excess Value Plus"
```

###Our Graph
Finally, we'll graph the two sets of data and illuminate what our issue is.
```{r}
plot1 <- plot(agg1$Age, agg1$`Average Salary`, xlab="Age", ylab="Salary Plus and Excess Value Plus", type = 'l', col = 'blue',
              ylim = c(-100,400))
par(new=TRUE)
plot2 <- plot(agg2$Age, agg2$`Excess Value Plus`, xlab="", ylab="", type = 'l', col = 'red',
              ylim = c(-100,400))
legend("topright", legend=c("Excess Value Plus", "Salary Plus"),
       col=c("red", "blue"), lty=1:1, cex=0.8)
```

As we can see from our plot, the most excess value comes from players in their early 20s, which is also where salary is the lowest. This initially seems like a huge breakthrough, with the solution being to simply acquire as many talented young players as possible.

However, this is akin to advising someone to invest in Apple and Microsoft in 1980. Of course, it's easy to look back and say that drafting Mike Trout or Mookie Betts was the best course of action, and to an extent it was. However, that doesn't provide any valuable information going forward.

Further, by nature of the MLB's contract structure, players are underpaid for the first 6 years of their careers. They're even more severely underpaid for the first three years of their careers, as they're playing for league minimum. That has a lot to do with why the salary plus statistic is below average (below 100) until players are roughly 28 or 29 years old.

Once a player reaches six years of service time, they're eligible for free agency, in which they can sign with any team in the league. These are the players we're interested in evaluating. We want to find guys who were readily available to every team in the league, and provided the most excess value for the teams that took a risk on them.

For this reason, it makes sense to subset our data to only include players who are 27 years old and older. If you look at the graph, there's a small peak in Excess Value Plus at 27, before a steep decline into a player's 30s. This could indicate that there is a small group of players who slipped through the cracks initially that provided great value in their late 20s at a very low cost.

##Subsetting our data

Since we want to limit our data to players who are 27 and older, we'll need to subset our data to only include those players. We'll also want to create an additional filter, limiting ourselves to players making less than 10 million dollars per year. The reason for this is that if a player is already making 10 million dollars, they aren't really a diamond in the rough. They've already been properly values by their team, and aren't exactly readily available for any team to pick up. Since we want to limit ourselves to players that are readily available, it makes sense to create this salary limit.

Our subset will be created as follows:
```{r}
age_salary_subset <- subset(Batting_Value_Salary, age > 26 & salary < 10000000)
```

#Finding breakout players

Now that we've limited oursevles to the appropriate players, ones that aren't young phenoms or already established high-paid players, we can identify certain breakout players that we'll build our model breakout player off of.

**Notes to self**

Based on that, we can take the Top however many players (5, 10, 25) and find their statistics in the year before their "breakout" seasons. Then we can aggregate those "seasons before" into one pre-breakout player. (As an aside, it may be good to pick and choose which players we use, for example maybe not Paul Goldschmidt since he was a top prospect, and maybe not the second or third Donaldson or Zobrist seasons). 

After we've created our pre-breakout player, we can go back into our main database and create our similarity score for all players compared to our pre-breakout player. From there, we can determine which players were "poised" for a breakout.


